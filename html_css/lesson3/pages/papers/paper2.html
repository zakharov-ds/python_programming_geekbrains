<!DOCTYPE HTML>
<html>
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <link rel="stylesheet" href="../../css/style.css" type="text/css"/>
		<title>Задачи, связанные с Big Data</title>
	</head>
	<body>
  		<h3 align="center" id = "up">Задачи, связанные с Big Data</h3>
 		<!-- комментарий-->
    <a href="../../index.html">На главную...</a>
    <p>
        <ul>
          <b>Меню</b>
          <li><a href="../paper.html">Статьи</a></li>
          <li><a href="../catalog.html">Каталог</a></li>
          <li><a href="../galery.html">Галерея изображений</a></li>
          <li><a href="../registration.html">Регистрация</a></li>
          <li><a href="../contacts.html">Контакты</a></li>
        </ul>
    </p>
    <br>
    <br>
 		<p><a href="#c2">Комментарии...</a></p>
    <hr>
	  <p align="justify">
<b>Задачи, связанные с&nbsp;Big Data</b><br>

Существуют три типа задач связанных с&nbsp;Big Data:
<ol>
<li> Хранение и&nbsp;управление<br>
Объем данных в&nbsp;сотни терабайт или петабайт не&nbsp;позволяет легко хранить и&nbsp;управлять ими с&nbsp;помощью традиционных реляционных баз данных.
</li>

<li> Неструктурированная информация<br>
Большинство всех данных Big Data являются неструктурированными. Т.е. как можно организовать текст, видео, изображения, и&nbsp;т.д.?
</li>

<li> Анализ Big Data<br>
Как анализировать неструктурированную информацию? Как на&nbsp;основе Big Data составлять простые отчеты, строить и&nbsp;внедрять углубленные прогностические модели?</li>
</ol>
</p>
<p align="justify">

<b>Хранение и&nbsp;управление Big Data</b><br>

Big Data обычно хранятся и&nbsp;организуются в&nbsp;распределенных файловых системах.

В&nbsp;общих чертах, информация хранится на&nbsp;нескольких (иногда тысячах) жестких дисках, на&nbsp;стандартных компьютерах.

Так называемая &laquo;карта&raquo; (map) отслеживает, где (на&nbsp;каком компьютере и/или диске) хранится конкретная часть информации.

Для обеспечения отказоустойчивости и&nbsp;надежности, каждую часть информации обычно сохраняют несколько раз, например&nbsp;&mdash; трижды.

Так, например, предположим, что вы&nbsp;собрали индивидуальные транзакции в&nbsp;большой розничной сети магазинов. Подробная информация о&nbsp;каждой транзакции будет храниться на&nbsp;разных серверах и&nbsp;жестких дисках, а&nbsp;&laquo;карта&raquo; (map) индексирует, где именно хранятся сведения о&nbsp;соответствующей сделке.

С&nbsp;помощью стандартного оборудования и&nbsp;открытых программных средств для управления этой распределенной файловой системой (например, Hadoop), сравнительно легко можно реализовать надежные хранилища данных в&nbsp;масштабе петабайт.


<br><b>Неструктурированная информация</b><br>

Большая часть собранной информации в&nbsp;распределенной файловой системе состоит из&nbsp;неструктурированных данных, таких как текст, изображения, фотографии или видео.

Это имеет свои преимущества и&nbsp;недостатки.

Преимущество состоит в&nbsp;том, что возможность хранения больших данных позволяет сохранять &laquo;все данные&raquo;, не&nbsp;беспокоясь о&nbsp;том, какая часть данных актуальна для последующего анализа и&nbsp;принятия решения.

Недостатком является&nbsp;то, что в&nbsp;таких случаях для извлечения полезной информации требуется последующая обработка этих огромных массивов данных.

Хотя некоторые из&nbsp;этих операций могут быть простыми (например, простые подсчеты, и&nbsp;т.д.), другие требуют более сложных алгоритмов, которые должны быть специально разработаны для эффективной работы на&nbsp;распределенной файловой системе.

Один топ-менеджер однажды рассказал StatSoft что он&nbsp;&laquo;потратил целое состояние на&nbsp;IT и&nbsp;хранение данных, но&nbsp;до&nbsp;сих пор не&nbsp;начал получать денег&raquo;, потому что не&nbsp;думал о&nbsp;том, как лучше использовать эти данные для улучшения основной деятельности.

Итак, в&nbsp;то&nbsp;время как объем данных может расти в&nbsp;геометрической прогрессии, возможности извлекать информацию и&nbsp;действовать на&nbsp;основе этой информации, ограничены и&nbsp;будут асимптотически достигать предела.

Важно, чтобы методы и&nbsp;процедуры для построения, обновления моделей, а&nbsp;также для автоматизации процесса принятия решений были разработаны наряду с&nbsp;системами хранения данных, чтобы гарантировать, что такие системы являются полезными и&nbsp;выгодными для предприятия.


<br><b>Анализ Big Data</b><br>

Это действительно большая проблема, связанная с&nbsp;анализом неструктурированных данных Big Data: как анализировать их&nbsp;с&nbsp;пользой. О&nbsp;данном вопросе написано гораздо меньше, чем о&nbsp;хранении данных и&nbsp;технологиях управления Big Data.

Есть ряд вопросов, которые следует рассмотреть.


<br><b>Map-Reduce</b><br>

При анализе сотни терабайт или петабайт данных, не&nbsp;представляется возможным извлечь данные в&nbsp;какое-либо другое место для анализа (например, в&nbsp;STATISTICA Enterprise Analysis Server).

Процесс переноса данных по&nbsp;каналам на&nbsp;отдельный сервер или сервера (для параллельной обработки) займет слишком много времени и&nbsp;требует слишком большого трафика.

Вместо этого, аналитические вычисления должны быть выполнены физически близко к&nbsp;месту, где хранятся данные.

Алгоритм Map-Reduce представляет собой модель для распределенных вычислений. Принцип его работы заключается в&nbsp;следующем: происходит распределение входных данных на&nbsp;рабочие узлы (individual nodes) распределенной файловой системы для предварительной обработки (map-шаг) и, затем, свертка (объединение) уже предварительно обработанных данных (reduce-шаг).

Таким образом, скажем, для вычисления итоговой суммы, алгоритм будет параллельно вычислять промежуточные суммы в&nbsp;каждом из&nbsp;узлов распределенной файловой системы, и&nbsp;затем суммировать эти промежуточные значения.

В&nbsp;Интернете доступно огромное количество информации о&nbsp;том, каким образом можно выполнять различные вычисления с&nbsp;помощью модели map-reduce, в&nbsp;том числе и&nbsp;для прогностической аналитики.


<br><b>Простые статистики, Business Intelligence (BI)</b><br>

Для составления простых отчетов&nbsp;BI, существует множество продуктов с&nbsp;открытым кодом, позволяющих вычислять суммы, средние, пропорции и&nbsp;т.п. с&nbsp;помощью map-reduce.

Таким образом, получить точные подсчеты и&nbsp;другие простые статистики для составления отчетов очень легко.


Прогнозное моделирование, углубленные статистики

На&nbsp;первый взгляд может показаться, что построение прогностических моделей в&nbsp;распределенной файловой системой сложнее, однако это совсем не&nbsp;так. Рассмотрим предварительные этапы анализа данных.

Подготовка данных. Некоторое время назад StatSoft провел серию крупных и&nbsp;успешных проектов с&nbsp;участием очень больших наборов данных, описывающих поминутные показатели процесса работы электростанции. Цель проводимого анализа заключалась в&nbsp;повышении эффективности деятельности электростанции и&nbsp;понижении количества выбросов (Electric Power Research Institute, 2009).

Важно, что, несмотря на&nbsp;то, что наборы данных могут быть очень большими, информация, содержащаяся в&nbsp;них, имеет значительно меньшую размерность.

Например, в&nbsp;то&nbsp;время как данные накапливаются ежесекундно или ежеминутно, многие параметры (температура газов и&nbsp;печей, потоки, положение заслонок и&nbsp;т.д.) остаются стабильными на&nbsp;больших интервалах времени. Иначе говоря, данные, записывающиеся каждую секунду, являются в&nbsp;основном повторениями одной и&nbsp;той&nbsp;же информации.

Таким образом, необходимо проводить &laquo;умное&raquo; агрегирование данных, получая для моделирования и&nbsp;оптимизации данные, которые содержат только необходимую информацию о&nbsp;динамических изменениях, влияющих на&nbsp;эффективность работы электростанции и&nbsp;количество выбросов.

Классификация текстов и&nbsp;предварительная обработка данных. Проиллюстрируем ещё раз, как большие наборы данных могут содержать гораздо меньше полезной информации.

Например, StatSoft участвовал в&nbsp;проектах, связанных с&nbsp;анализом текстов (text mining) из&nbsp;твитов, отражающих, насколько пассажиры удовлетворены авиакомпаниями и&nbsp;их&nbsp;услугами.

Несмотря на&nbsp;то, что ежечасно и&nbsp;ежедневно было извлечено большое количество соответствующих твитов, настроения, выраженные в&nbsp;них, были довольно простыми и&nbsp;однообразными. Большинство сообщений&nbsp;&mdash; жалобы и&nbsp;краткие сообщения из&nbsp;одного предложения о&nbsp;&laquo;плохом опыте&raquo;. Кроме того, число и&nbsp;&laquo;сила&raquo; этих настроений относительно стабильны во&nbsp;времени и&nbsp;в&nbsp;конкретных вопросах (например, потерянный багаж, плохое питание, отмена рейсов).

Таким образом, сокращение фактических твитов до&nbsp;скора (оценки) настроения, используя методы text mining (например, реализованные в&nbsp;STATISTICA Text Miner), приводит к&nbsp;гораздо меньшему объему данных, которые затем могут быть легко сопоставлены с&nbsp;существующими структурированными данными (фактические продажи билетов, или информация о&nbsp;часто летающих пассажирах). Анализ позволяет разбить клиентов на&nbsp;группы и&nbsp;изучить их&nbsp;характерные жалобы.

Существует множество инструментов для проведения такого агрегирования данных (например, скор настроений) в&nbsp;распределенной файловой системе, что позволяет легко осуществлять данный аналитический процесс.


<br><b>Построение моделей</b><br>

Часто задача состоит в&nbsp;том, чтобы быстро построить точные модели для данных, хранящихся в&nbsp;распределенной файловой системе.

Существуют реализации map-reduce для различных алгоритмов data mining/прогностической аналитики, подходящих для масштабной параллельной обработки данных в&nbsp;распределенной файловой системе (что может быть поддержано с&nbsp;помощью платформы STATISTICА StatSoft).

Однако, именно из-за того, что вы&nbsp;обработали очень большое количество данных, уверенны&nbsp;ли вы, что итоговая модель является действительно более точной?

На&nbsp;самом деле, скорее всего, удобнее строить модели для небольших сегментов данных в&nbsp;распределенной файловой системе.

Как говорится в&nbsp;недавнем отчете Forrester: &laquo;Два плюс два равняется 3,9&nbsp;&mdash; это обычно достаточно хорошо&raquo; (Hopkins &amp;&nbsp;Evelson, 2011).

Статистическая и&nbsp;математическая точность заключается в&nbsp;том, что модель линейной регрессии, включающая, например, 10&nbsp;предикторов, основанных на&nbsp;правильно сделанной вероятностной выборке из&nbsp;100&nbsp;000&nbsp;наблюдений, будет так&nbsp;же точна, как модель, построенная на&nbsp;100 миллионах наблюдений.

В&nbsp;вероятностной выборке каждый элемент совокупности имеет определенную, заранее заданную вероятность быть выбранным. Причем для каждого элемента совокупности вероятность попадания в&nbsp;выборку одинакова.

В&nbsp;противоположность этому, некоторые поставщики в&nbsp;области Big Data, часто для рекламы, заявляют, что &laquo;все данные должны быть обработаны&raquo;.

В&nbsp;действительности, точность модели зависит от&nbsp;качества выборки (каждое наблюдение в&nbsp;популяции должно иметь известную вероятность выбора) и&nbsp;её&nbsp;размер связан со&nbsp;сложностью модели. Размер популяции не&nbsp;имеет значения.

Именно по&nbsp;этой причине, например, выборка, состоящая всего из&nbsp;нескольких тысяч голосов, может позволить построить очень точные прогнозы реальных результатов голосования.

Итак, реальная значимость Big Data в&nbsp;распределенных файловых системах состоит не&nbsp;в&nbsp;том, чтобы построить прогностические модели на&nbsp;основе всех данных; точность моделей не&nbsp;будет выше.

Более значимым является использование всего объема данных для сегментации и&nbsp;кластеризации, что позволит эффективно строить большое количество моделей для небольших кластеров.

Например, можно ожидать, что модели, основанные на&nbsp;широкой сегментации (20-30&nbsp;лет), будут менее точными, чем большое число моделей, построенных на&nbsp;более детальной сегментации (например, 20-21-летние студенты, проживающие в&nbsp;общежитии, и&nbsp;учащиеся на&nbsp;факультете бизнеса).

Таким образом, один из&nbsp;способов получения преимуществ Big Data заключается в&nbsp;том, чтобы использовать доступную информацию для построения большого количества моделей для большого числа сегментов&nbsp;и, затем, по&nbsp;соответствующей модели строить прогнозы.

В&nbsp;предельном случае, каждый отдельный &laquo;человек&raquo; в&nbsp;большом хранилище данных клиентов может иметь свою собственную модель для прогнозирования будущих покупок.

Это означает, что аналитическая платформа (например, STATISTICA Enterprise), поддерживающая хранилища данных, должна быть в&nbsp;состоянии управлять сотнями или даже тысячами моделей, и&nbsp;иметь возможность перенастраивать&nbsp;их, когда это необходимо.


<br><b>Интеграция со&nbsp;STATISTICA</b><br>

Выборка, сокращение данных, отбор данных с&nbsp;помощью map-reduce. Что это означает для анализа Big Data?

Существуют эффективные (map-reduce) алгоритмы получения выборки, доступные для распределенных файловых систем, с&nbsp;помощью которых Big Data становятся пригодными для построения прогностических моделей.

Для решения многих задач это очень удобный способ, например, развертывание STATISTICA Enterprise и&nbsp;Data Mining платформы над интерфейсом данных в&nbsp;распределенной файловой системе для выполнения операций подготовки данных/агрегирования и/или вероятностной выборки, использующих алгоритмы map-reduce (и&nbsp;управлемых платформой Enterprise).

В&nbsp;дополнение, можно также строить детальные выборки (например, на&nbsp;основе микросегментации специфичных групп клиентов) и&nbsp;предоставлять данные STATISTICA для построения моделей для специфичных сегментов.

Интеграция STATISTICA с&nbsp;open-source инструментами. Уникальное достоинство STATISTICA Enterprise и&nbsp;Data Mining платформы в&nbsp;том, что она специально разработана как корпоративная платформа с&nbsp;использованием стандартных интерфейсов для сценариев и&nbsp;данных.

Это значит, что не&nbsp;только инструменты StatSoft, но&nbsp;и&nbsp;open-source инструменты, а&nbsp;также специализированная аналитика с&nbsp;использованием алгоритмов map-reduce, могут быть легко интегрированы в&nbsp;платформу STATISTICA, управляться через неё как отдельный узел в&nbsp;рабочей среде.

Например, платформа&nbsp;R, часто используемая аналитиками для проведения специализированных вычислений, легко взаимодействует со&nbsp;STATISTICA. Скрипты R&nbsp;уже много лет, как могут быть выполнены из&nbsp;среды STATISTICA.

Методы анализа Big Data появляются и&nbsp;развиваются очень быстро. Важно, чтобы аналитическая платформа для распределенной файловой системы могла легко использовать новые методы подготовки и&nbsp;агрегирования данных, выборки и&nbsp;стратификации.

Реализации специализированных процедур map-reduce. В&nbsp;дополнение к&nbsp;легкой интеграции с&nbsp;open-source и&nbsp;другими инструментами и&nbsp;платформами, не&nbsp;менее важно, что аналитическая платформа STATISTICA обеспечивает возможность гибкой настройки рабочей среды аналитика для решения конкретных задач на&nbsp;основе распределенной файловой системы и&nbsp;Big Data.

Появляются и&nbsp;развиваются различные методы анализа и&nbsp;использования Big Data, и&nbsp;на&nbsp;данный момент нет &laquo;традиционных&raquo; прогностических методов, стандартных подходов, которые были&nbsp;бы хорошо задокументированы.

Однако данная ситуация может измениться довольно быстро, так как все крупнейшие поставщики баз данных и&nbsp;BI инструментов (Microsoft, Oracle, Teradata, и&nbsp;другие) оперативно предоставляют интерфейсы и&nbsp;инструменты для доступа и&nbsp;обработки данных.

Так или иначе, платформа STATISTICA Enterprise предоставляет вам возможность пользовательской настройки конкретных аналитических подходов, основанных на&nbsp;данных в&nbsp;распределенных файловых системах, а&nbsp;также поддерживает нестандартные интерфейсы и&nbsp;инструменты.


<br><b>Критика Big Data</b><br>

Хранение Big Data не&nbsp;всегда приводит к&nbsp;получению выгоды

Хранение огромного количества данных, описывающих некоторые легко наблюдаемые события, не&nbsp;всегда приводит к&nbsp;выгодному понимаю реальности.

Это в&nbsp;равной мере относится к&nbsp;анализу акций, каналов twitter, медицинских данных, данных CRM, или мониторингу комплекса оборудования для диагностического обслуживания.

Например, достоверный список потенциальных покупателей товаров, наряду с&nbsp;демографической информацией, а&nbsp;также информацией о&nbsp;чистой стоимости товаров, могут быть гораздо более ценными для поставщиков, чем массивное хранилище данных о&nbsp;кликах на&nbsp;различных сайтах онлайн-магазинов.

При мониторинге работы электростанций, мы&nbsp;узнали, [и&nbsp;продемонстрировали, см. Electric Power Research Institute (EPRI), 2009], что обращение внимания именно на&nbsp;определенные фрагменты информации и&nbsp;на&nbsp;изменения, которые происходят в&nbsp;некоторых параметрах (или их&nbsp;комбинациях), более информативны для последующего представления, чем мониторинг тысячи параметров потоков данных за&nbsp;каждую секунду.

Как и&nbsp;в&nbsp;случае любого проекта по&nbsp;оптимизации организационной или коммерческой деятельности, важно начать с&nbsp;вопросов: &laquo;Как должны в&nbsp;идеале выглядеть результаты?&raquo;, &laquo;Как я&nbsp;могу измерить успех?&raquo; и&nbsp;&laquo;Какая информация более информативна и&nbsp;полезна для достижения идеального результата?&raquo;.

Ответы на&nbsp;эти вопросы вполне могут привести к&nbsp;реализации хранилища Big Data, однако во&nbsp;многих случаях&nbsp;&mdash; могут и&nbsp;не&nbsp;привести.

Скорость обновления данных и&nbsp;&laquo;актуальный&raquo; временной интервал

Может случиться, что вы&nbsp;строите модели на&nbsp;производстве, предсказывающие неполадки на&nbsp;одну секунду вперед на&nbsp;основе непрерывного потока данных для тысяч параметров. Однако если это требует, чтобы инженер два часа детализировал результат и&nbsp;&laquo;что-то делал&raquo;, то&nbsp;такая система может быть бессмысленной.

Для поставщиков домашней фурнитуры, было&nbsp;бы важнее получить &laquo;сигнал&raquo; за&nbsp;месяц или два перед тем, как осуществится покупка жилья, вместо информации в&nbsp;режиме реального времени уже после покупки, когда потенциальный клиент просматривает различные Интернет-сайты в&nbsp;поисках фурнитуры.

Раннее оповещение позволило&nbsp;бы поставщикам завести контакты с&nbsp;потенциальным клиентом, предоставить специальные предложения&nbsp;и, возможно, побудить посетить магазин.

В&nbsp;целом, следует начинать с&nbsp;четкого определения необходимых параметров и&nbsp;стратегии того, как добиться успехов в&nbsp;той или иной области.

После этого уже будет очевиден необходимый временной интервал обновления данных, а, следовательно, и&nbsp;требования к&nbsp;оптимальному плану сбора данных, их&nbsp;хранению и&nbsp;анализу.


<br><b>Итоги</b><br>

Цель данной статьи&nbsp;&mdash; дать краткий обзор определенных сложностей, связанных с&nbsp;Big Data: хранилищами данных объемом в&nbsp;терабайт, петабайт (и&nbsp;больше), технологиями и&nbsp;подходами для преодоления сложностей получения значимой информации из&nbsp;Big Data.

Итак, создание и&nbsp;поддержка хранилищ объемом в&nbsp;терабайт, петабайт и&nbsp;более стало возможным благодаря технологиям распределенных файловых систем.

В&nbsp;распределенных системах, вместо хранения данных в&nbsp;одной файловой системе, данные сохраняются и&nbsp;индексируются на&nbsp;нескольких (и&nbsp;даже тысячах) жестких дисках и&nbsp;серверах. Создается также &laquo;карта&raquo; (map), где содержится информация о&nbsp;том, где именно находятся те&nbsp;или иные данные.

Hadoop является одной из&nbsp;самых известных систем, использующих данный подход.

Чтобы обработать данные в&nbsp;распределенной файловой системе, необходимо проводить низкоуровневые вычисления, такие как суммирование, агрегирование и&nbsp;др. в&nbsp;месте их&nbsp;физического размещения в&nbsp;распределенной файловой системе. Создать карту (map) проведенных вычислительных алгоритмов и&nbsp;отслеживать локальные результаты. Затем, аккумулировать результаты (reduced). Данный подход и&nbsp;шаблон проведения вычислительных алгоритмов получил название Map-Reduce.

На&nbsp;практике, анализ Big Data редко заключается в&nbsp;том, чтобы вычислить статистические итоги по&nbsp;всем данным. Вместо этого значимость Big Data заключается в&nbsp;возможности разделения данных на&nbsp;&laquo;микро-сегменты&raquo; и&nbsp;с&nbsp;помощью методов data mining и&nbsp;прогностического моделирования построить большое число моделей для небольших групп наблюдений.

С&nbsp;точки зрения реализации, аналитическая платформа для работы с&nbsp;Big Data должна уметь использовать новые технологии map-reduce.

Платформа STATISTICA Enterprise и&nbsp;Decisioning предоставляет все возможности для эффективной работы с&nbsp;Big Data, а&nbsp;также позволяет управлять тысячами моделей, применяемых в&nbsp;отношении таких данных.
	  	</p>
	  	<hr>
		<p id="c2" class="leftstr">
			Комментарии к статье
		</p>
		<p class="rightstr">
			<a href="#up">Наверх...</a>
		</p>	
		<p>
			Взято из истоника <a href="http://www.statsoft.ru/products/Enterprise/big-data.php" target="_blank"> Статсофт </a><br>
			Коммент2.....<br>
			Коммент3.....<br>
			Коммент4.....<br>
			Коммент5.....<br>
		</p>
 	</body>
 	<footer>
 		<hr>
 		ZakharovDS&copy;
 	</footer>
</html>